import cv2
import pathlib
import itertools
import filetype

import tensorflow as tf 
import numpy as np
import pandas as pd

from typing import List

# scripts
from ..data.classes import *
from ..data.io import *
from ..processing.image_ops import * 
from ..training.augmentation import * 
from .decorators import * 




class Utils():

    
    def __init__(self, config):
        
        self.config = config
        
        # initialize
        self.data_io = DataIO()
        self.image_ops = ImageOperations()
        
        


    def threshold_prediction(self, prediction):

        prediction = self.image_ops.binary_threshold(
            prediction,
            self.config["deeplab"]["threshold"]
        )
        
        prediction = self.image_ops.to_range_0_255(prediction)
 
        return prediction
    

        

    def process(self, data_point, image_only = False, mask_only = False):
        image = self.image_ops.read_image_or_mask(
            data_point.image.path,
            resize_dims = (512,512)
        )
        image = self.image_ops._change_fundus_background_color(image)
        image = self.image_ops._apply_clahe(image)
        image = self.image_ops.to_range_0_1(image)

        mask = self.image_ops.read_image_or_mask(
            data_point.mask.path,
            resize_dims = (512,512),
            as_grayscale = True
        )
        mask = self.image_ops.to_range_0_1(mask)

        if image_only == True:
            return image
        elif mask_only == True:
            return mask 
        else:
            return  image, mask
                                

    
    def tensorflow_dataset_handler(self, datapoints: List[Datapoint]):
        # Convert each Pydantic object to a format TensorFlow can understand
        def generator():
            for data_point in datapoints:
                yield self.process(data_point)
            
        return generator

    
    def create_tf_dataset(self, dataset : np.ndarray, apply_augmentation = False):

        example = dataset[0]
        image_shape = example.image.shape
        mask_shape = example.mask.shape
        
        output_signature = (
            tf.TensorSpec(shape = image_shape, dtype = tf.float32),
            tf.TensorSpec(shape = mask_shape, dtype = tf.float32)
        )

        
        if apply_augmentation == True:
            
            return (
                tf.data.Dataset.from_generator(
                    self.tensorflow_dataset_handler(dataset),
                    output_signature = output_signature,
                )
                .cache()
                .map(Augment(), num_parallel_calls = tf.data.AUTOTUNE)
                .batch(self.config["training"]["batch_size"])
                .prefetch(buffer_size = tf.data.AUTOTUNE)
            )
        else:
            return (
                tf.data.Dataset.from_generator(
                    self.tensorflow_dataset_handler(dataset),
                    output_signature = output_signature,
                )
                .cache()
                .batch(self.config["training"]["batch_size"])
                .prefetch(buffer_size = tf.data.AUTOTUNE)
            )



    def get_ids_from_dataset(self, dataset_dict):
        id_dict = {}
        for dataset_name, dataset_items in dataset_dict.items():
            id_dict[dataset_name] = [x.id for x in dataset_items]
        return id_dict
    
